{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Notebook: Machine Learning and Ensemble Methods on MRI Data for AD and CN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Exploration and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1: Plot Feature Histograms and Distributions\n",
    "\n",
    "- Objective: Understand the range, spread, and shape of individual feature distributions.\n",
    "- Instructions: Choose two or three features from the dataset and plot their histograms. Describe any observations regarding the shape of these distributions (e.g., normal, skewed) and their implications for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: Correlation Heatmap of Features\n",
    "\n",
    "- Objective: Explore relationships and potential multicollinearity among features.\n",
    "- Instructions: Generate a correlation matrix and plot it as a heatmap. Identify any features with strong correlations and discuss whether they might provide redundant information to a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset Size Reduction Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Train Models with Reduced Dataset Sizes\n",
    "\n",
    "- Objective: Examine how model performance changes with a smaller dataset.\n",
    "- Instructions: Create three different subsets of the dataset, sampling 20%, 50%, and 80% of the full data. Train all the models that were taught in the notebook on each subset, then evaluate and compare the model performance metrics with those of the full dataset. Record your results in a table and discuss any observed trends or changes.\n",
    "- How to find optimum `n_components` for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Visualize Learning Curves\n",
    "\n",
    "- Objective: Show how dataset size influences learning and performance.\n",
    "- Instructions: Choose one model and plot a learning curve, showing accuracy as a function of training size. Interpret the learning curve to discuss how performance is affected by training data quantity and identify any signs of underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cross-Validation and Model Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: Apply k-Fold Cross-Validation\n",
    "\n",
    "- Objective: Understand how cross-validation provides stable accuracy estimates.\n",
    "- Instructions: Implement 5, 10, and 20-fold cross-validation for all the models that were taught in the notebook and plot the accuracy across each fold. Discuss any observed variance among folds and what it implies about the modelâ€™s stability on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
